---
title: "Tidy (Art Historical) Data"
author: "Matthew Lincoln"
date: "September 9, 2015"
output:
  ioslides_presentation:
    incremental: true
---

```{r opts, message=FALSE, warning=FALSE, echo=FALSE}
library(knitr)
library(londonauctions)
library(dplyr)
library(ggplot2)
knitr::opts_chunk$set(message=FALSE, warning=FALSE, echo=FALSE)
```

# Making a tidy table

## What _is_ tidy data?

1. One concept per table
1. One variable per column
1. One value per cell
1. Consistent data types

## Why?

1. Make it easy to analyze at scale
2. Make it easy to share
3. Make it easy to recombine with other data

## What might our data look like?

```{r raw_sales}
messy_data <- data_frame(
  acq_no = c("1999.32", "1908.54", "1955.32", "1955.33"),
  artist_1 = c("Studio of Rembrandt", "Jan Vermeer", "Vermeer, Jan", "Hals, Frans"),
  artist_2 = c("possibly Govaert Flinck", NA, NA, NA),
  date = c("after 1636", "c. 1650", "c. 1655", "16220"),
  medium = c("oil on canvas", "oil on panel", "oil on canvas", "oil on canvas, relined"),
  tags = c("religious, portrait", "genre, woman", "woman, window, painting", "merry company")
)

clean_data_obj <- data_frame(
  acq_no = messy_data$acq_no,
  date = c(1636, 1650, 1655, 1620),
  date_qual = c("after", "circa", "circa", NA),
  medium = rep("oil", 4),
  support = c("canvas", "panel", "canvas", "canvas"),
  cons_note = c(NA, NA, NA, "relined")
)

clean_data_artist <- data_frame(
  acq_no = c("1999.32", "1999.32", "1908.54", "1955.32", "1955.33"),
  name = c("Rembrandt", "Govaert Flinck", "Jan Vermeer", "Jan Vermeer", "Frans Hals"),
  qualification = c("studio of", "possibly", NA, NA, NA)
)

clean_data_tags <- data_frame(
  acq_no = c("1999.32", "1999.32", "1908.54", "1908.54", "1955.32", "1955.32", "1955.32", "1955.33"),
  tag = c("religious", "portrait", "genre", "woman", "woman", "window", "painting", "merry_company")
)

messy_data %>% kable()
```

## One variable per column

```{r}
messy_data %>% kable()
```

- `artist_1`: first and last names combined; conditionals
- `date`: conditionals
- `medium`: medium and support combined; conditionals

## One value per cell

```{r}
messy_data %>% kable()
```

- `tags` needs to be its own table

## Consistent types and values

```{r}
messy_data %>% kable()
```

- `date` has typos
- `date` could potentially be numeric

# Tidied data

## Objects

```{r}
clean_data_obj %>% kable()
```

## Object-Artist

```{r}
clean_data_artist %>% kable()
```

## Object-Tags

```{r}
clean_data_tags %>% kable()
```

---

```{r, echo=TRUE}
clean_data_obj %>% 
  inner_join(clean_data_tags, by = "acq_no") %>% 
  filter(tag == "woman") %>% 
  kable()
```

---

```{r, echo = TRUE}
clean_data_obj %>% 
  inner_join(clean_data_artist, by = "acq_no") %>%
  filter(is.na(qualification) | qualification != "studio of") %>% 
  ggplot(aes(x = name, y = date, color = date_qual)) + 
  geom_point(size = 5)
```

# Documenting tidy data

## Do it for future-you & for others

- You **will** forget what you did in a few monts. Or even a few days.
    - Makes writing reports/articles easier, too!
- Make your data reusable
    - others won't have to guess at what a certain column means
    - what decisions you made when recording it
    - how to cite it
    - licensing for reuse

## Show your work

- Describe what you made:
    - Keep a plain text doc in the same directory as your tables
    - Have a heading for each table
    - List every column name and describe what it means
        - Incl. list of possible values, relation to other tables as appropriate
- Document the process
    - Did you adapt this from another dataset? (incl. original data, or link)
    - Describe the transformations you made, including what software you used

## Make changes programmatically

- [OpenRefine](http://programminghistorian.org/lessons/cleaning-data-with-openrefine) exports a JSON file with changes
- R, Python code makes changes and documents them at the same time

![r code comments](img/r_comments.png)

# Sharing tidy data

## Flat Files, Not Live Servers

Omeka and the like are great for interactively communicating stories and selections from your research. They are not a storage and dissemination solution _in the long run_. Costly, fragile, limiting.

"Flat files" are decoupled from running software, and can be opened by a regular text editor. Someone without your original software has a better chance of recovering the information.

## Plaintext

- Use plaintext file types for tables and docs (`.txt`, `.csv`, not `.xslx`)
    - Free
    - Somewhat more future-proof
    - Trackable
- Creating in Excel/Google Sheets is fine, you can export it
    - When saving in Excel, use `UTF-8` so that accents & special characters are preserved
- Don't use menaingful formatting (colored cells, bold, italics, borders)
- Save multiple versions

## Archive it

- Bundle data and documentation in the same directory and zip them.
- Distribute
    - Institutional repository (upload it with your dissertation)
    - Journal websites
    - [Zenodo](https://zenodo.org/)
    - [Git](https://git-scm.com/) (works great with all-text files - more and more libraries and journals will be moving towards this method for tracking file versions)

## Resources

- Database management
    - [Google Fusion Tables](https://www.google.com/fusiontables/)
    - [UCLA DH101: Data and Databases](http://dh101.humanities.ucla.edu/?page_id=93)
    - [Designing Databases for Historical Research](http://port.sas.ac.uk/mod/book/view.php?id=75) (great intro to relational DBs)
- Data cleaning
    - [OpenRefine](http://programminghistorian.org/lessons/cleaning-data-with-openrefine)
